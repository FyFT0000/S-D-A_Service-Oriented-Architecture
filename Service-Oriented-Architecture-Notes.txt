https://www.coursera.org/learn/service-oriented-architecture?specialization=software-design-architecture

Service-Oriented Architecture
    Based on an understanding of architectural styles, you will review architectures for web applications, then explore the basics of Service-Oriented Architecture (SOA) in two approaches: Web Services (WS*) and Representational State Transfer (REST) architecture. 



4.1.1 – Introduction to Service-Oriented Architecture
A service is external to the software requesting it, and often remove – either in another service in the company or somewhere on the internet. Services are often associated with two roles:
    _1. the service requester, which is the software requesting the service.
    _2. the service provider, which fulfills requests.
 These roles echo client and server roles in similar domains, so sometimes these terms are used interchangeably.
 _   Service-Oriented Architecture (SOA): examines how to build, use, and combine services. Instead of creating large software suites that do everything, service-oriented architecture reaches software goals by building and using services, and designing an architecture that supports their use. This course will cover software-oriented architecture in two contexts:
    _1. on the Internet (also known as “external” to an organization)
    _2. in large organizations (also known as “internal” to the organization)
_   Web Services: are services that are offered on the Internet. It is possible to build feature-full apps on the Internet by using existing web services external to your application to fulfill some of the tasks. For instance, a web application for travelling may take advantage of services that obtain flight prices on the internet, services that obtain hotel prices, or car rental services. Essentially, a number of services only had to be combined to create an application.
    _Web services may entail trade-offs. The ease of using existing services must be balanced against qualities of the services, which is not under the control of developers. In these cases, non-functional requirements become very important. These might include:  Response Time  Supportability  Availability, of the service, as determined by outside parties.
_   Large Organizations or enterprises: code that is built in-house can be turned into services. In turn, these services can be used by different parts of the business, or by adding interfaces to existing software. These services can then be used to drive business or organizational goals. For example, a company might offer an interface for software systems in various departments to request information about support costs in their software. Support costs are offered as a service that departments can query.
    _Internal service-oriented architecture encourages organizations to build general, reusable software services that can be used and combined as needed. This architecture allows businesses to respond to opportunities quickly, and makes services easier to access for new business units.
    _Developing an extensive service-oriented architecture (SOA) can present trade-offs for large organizations. A full switch to SOA is costly, and it can be difficult to support despite its benefits. In these cases, services are often introduced bit by bit, separating out the most useful, cross-departmental functions first.
    _Like any other architecture, SOA requires trade-offs and design decisions in implementation, whether it is through web services or in-house organizational services. Additionally, SOA is not easy. Once in place, however, SOAs are powerful, as they provide modularity, extensibility, and code reuse. Applications can be built through combining services. New services can be created by combining existing services, either from the ground up, or through the addition of interfaces to existing code.

4.1.2 – Service Principles
In order to create useful and reusable services, and by extension, service-oriented architecture (SOA), there are certain best practices, guidelines, and principles that have been developed that outline the desired properties that services should have. These desired properties for services are outlined in the table below.
_   Modular and Loosely Coupled: Services should be module and loosely coupled. This allows services to be reusable and combinable – in other words, services can be mixed and matched if they are modular. In object-oriented programming, loose coupling is achieved by exposing only the relevant elements of a class or component to its client. In SOA, requests are made by passing communication to the service in a way that aligns with its interface. The service performs the necessary operations and then passes back a communication containing the result of the service or a confirmation that the request was fulfilled.
_   Composable: Services should be used in combination, in order to create usable applications or other services. In order to achieve this property, services should be modular. Just like objects can be combined in object-oriented programming to provide the desired behaviour, services should be able to combined to provide a desired end- goal in SOA.
_   Platform- and Language- Independent: Services should be platform independent and language independent. For example, a service coded in Java can be used by a service requester coded in Ruby. To achieve platform- and language- independence, communication standards and protocols must be followed. For example, services on the Internet are often requested with an XML file or HTTP request.
_   Self-Describing: A service should describe how to interact with it. In other words, a service should describe its own interfaces. This includes what input the service takes, and what output the service gives. There are formal standards for describing services, including web service description language (WSDL).
_   Self-Advertising: Services must make known to potential clients that it is available. In-house organizations may create service catalogues, while distributed applications using web services have standards like Universal Description, Discovery, and Integration (UDDI) to connect service providers with potential service requesters.

4.1.3 - Web Systems Evolution
Often, the terms “Internet” and “World Wide Web” are used interchangeable. However, these terms actually refer to two different, but interrelated things. The Internet was actually invented almost 20 years before the World Wide Web!
_   In 1969, a small computer network called ARPANET was created and used by researchers in the United States, in order to send a small amount of data between pairs of computers. This was the first-time data was sent across a computer network. In the following years, small networks were developed at research institutions across the United States. Further, these networks began to connect with each other. Once this network of networks reached a global scale, the Internet was born.
_   The World Wide Web, otherwise known as “the web” led to standards and technologies for computer-based communication over the Internet. Web standards include Hypertext Markup Language (HTML), and Hypertext Transport Protocol (HTTP). The introduction of HTML and web browsers in the early 1990s, which allowed users to view websites, greatly increased the popularity of the web.
_   Websites are made up of web pages. To view a web page, the web browser makes a request to the web server that hosts the web page, then the web server handles the request by returning the HTML document that corresponds to the requested web page, and then the browser renders this HTML document to the user. The relationship between web browser and web service is a client-server relationship. Both the request and the response are messages conveyed in HTTP, a communication protocol that both the web browser and web server understand.
_   Static Web Pages: Initially, the web consisted of static web pages, which were web pages stored on the server as a separate HTML file. When a static web page is viewed on a web browser, the HTML rendered on the screen is the same HTML document stored on the web server. The document on the web server has not changed or been customized before being served to the client. In order to change the web page, the corresponding HTML document must be changed. Under this model, even small changes to a web page may require the update of many HTML documents to maintain consistency across the whole website. Since changes require manual developer intervention, static websites are best used for presenting information that does not change very often, like personal websites or publications.
_   Dynamic Web Pages: Beginning in 1993, dynamic web pages began to emerge in response to the lack of customizability and scalability imposed by static web pages. Dynamic web pages are generated at the time of access. This means that the web page does not exist on a server before it is generated. When a dynamic web page is viewed, the web server passes on the request to an application to handle. The application can perform a computation, lookup some information in a database, or request information from a web service, which produces dynamic content as output. The application can generate an HTML document for the server, and then the server sends that back to the web browser, which can then display it for a user.
    _Making changes to dynamic websites is much easier than for static web pages. Changes need only be applied to one database element or variable in the application to make a change throughout a dynamic website.
    _Dynamic web pages provide many advantages. They can be customized for the view, they can respond to external events, they generally provide increased functionality compared to their static counterparts, and they are easier for a developer to modify. Currently, dynamic web pages dominate the web, including many types of webpages such as personal blogs and news feeds.
    _Although it is not always easy to determine if a website is statically or dynamically generated, a good rule of thumb is that more complex websites tend to be dynamic. Static webpages are still excellent tools to use for web pages whose content does not need to be personalized or does not change often.
_   Web Applications: A growing trend in web-based systems is the use of web-based applications, otherwise known as web applications. Web applications, like desktop applications, provide graphical user interfaces that allow users to interact with them, but a web application is run in a web browser and is stored on a remote web server, whereas a desktop application is run and stored locally on a computer.
    _Web applications are platform independent. This means that they can run on any operating system, provided that a compatible web browser is installed. Web applications eliminate the need for users to download and maintain application software on a computer. However, web applications also require users to have Internet access, because web applications communicate information through HTTP with a web server and/or application server on the backend.
    _Web applications provide users with a richer, more interactive web experience than simpler dynamic or static web pages. Web applications enable everything from online banking, online learning, online games, calculators, calendars, and more.
_   Web Services: If web applications or websites integrate with web services, real-time information can be used to create more complex, richer applications. Web services, in turn, can rely on other services. Web services can be used to satisfy specific needs, such as stock market data, weather reports, or currency conversion.
    _By treating web services like reusable components, information produced by these web services can be used by many different web applications at the same time. Web applications and web services communicate over the web using open standards like HTTP, XML, and JSON, which are easy for machines to manipulate.
    _Web services can be accessed through programmatic means, or services provide a user interface that can be embedded in a web page or application. By using web services, request and response of different services is asynchronous. This means that the logic is designed to continue running instead of waiting for a response. A page composed of many services can be generated while the individual services are processing requests and sending responses.

4.1.4 – Web Systems Architecture

Layered: 
In the third course of this specialization, the term layer was defined as a collection of components that work together toward a common purpose. Layers help identify hierarchies in a system. Knowledge of layers helps software designers restrict how layers interact with each other: components in a layer only interact with components in their own layer or adjacent layers, and this may only be done through interfaces provided by each component. Generally, lower layers provide services to layers above them.
_   More complex systems often require more layers to help logically separate components. However, the trade-off to adding more layers is that performance suffers, due to an increase in communication required between layers. Layers are often conceptually organized into presentation, application, and data tiers. In a web-based system, the presentation tier is further divided into two layers: one for the web browser, and one for the web server.
_   Each layer of a web-based system has a function:
    _The web browser layer is the topmost layer of the system. It displays information to the user.
    _The web server layer is directly below the web browser layer. It receives the request from the web browser, obtains the requested content, and returns it to the browser.
    _The application layer is below the web server layer. It is responsible for ensuring the function or service provided by the system is performed.
    _The bottom layer is the data layer. This layer is responsible for storing, maintaining, and managing data. Access to data may be read-only, or may allow for both reading and writing. Depending on the system, this access can be in the form of a filesystem or database.

Layers for Static Web Content:
A static web page has a layered architecture of a web browser layer, a web server layer, and a data layer.
_   The web browser layer typically consists of a web browser, which displays information provided by the web server. The web server layer receives the request from the web browser, and retrieves the appropriate HTML document stored in the data layer. Once the access to the right HTML document is secured, this layer returns the requested content to the browser.
_   The data layer consists of HTML documents that are delivered back to the web browser unchanged by the web server. As HTML documents do not change, the filesystem can be read-only.
_   There is no application layer in a static web content system, as the HTML documents served by the web server are the exact as stored in the file system. No processing has been applied.

Layers for Dynamic Web Content and Web Applications:
In a dynamic web content system, a layered architecture requires a web browser layer, web server layer, application layer, and data layer.
_   As with static web content, the web browser layer typically consists of a web browser, which displays information provided by the web server. Similarly, the web server layer receives the request from the web browser, and returns the requested content to the browser. Unlike a static web page, however, on a dynamic web page, HTML documents are generated when they are requested by a web browser. The web server passes on the request to an application server in the application layer for processing.
_   The application layer for dynamic web pages can consist of one or more programs or applications that process the request to generate the resulting content. The application layer may also call upon other web services, and read and write data to a database via the data layer. This same layering scheme also applies to architectures for complex web applications.

Services View:
An alternative view of the architecture can be considered through a UML component diagram. A web-based system can be thought of as a collection of services and service requester/provider pairings.
_   For example, the database provides data services, and the application server is a server requester to the database. The application server runs programs that may access a variety of web services provided outside the system. Those web services may themselves access other services.
_   Layered architecture and use of outside web services reinforces the basic design principles of separation of concerns and code reuse. Layers have specific responsibilities, while outside services provide functionality that the system does not have to implement. The scope of using web services is huge, so it raises the challenge of identifying the right ones to use.

4.1.5 – HTML / XML / JSON
HTML and XML are markup languages, while JSON is a popular, lightweight data-interchange format used in many web applications today. Markup languages are designed to adorn text in a machine and human readable way, typically to add meaning or structure. Markup languages use tags to mark how certain pieces of text are interpreted. Tags are often standard words that can be defined for some meaning on purpose. 

HTML:
Hypertext Markup Language (HTML) is the markup language used to structure text on web pages. Note that HTML provides structure to web pages, but not styling. For example, HTML marks what parts of the page text are the title, headings, paragraphs, etc., so that they can be rendered appropriately by a web browser. HTML has a predefined set of tags that serve different purposes.
_   The DOCTYPE tag is the first line in any HTML file, and denotes to the browser that the content is HTML. The rest of the document is contained with the <html> tags. In general, HTML documents have two sections: the head and the body. These are contained within the <head> and <body> tags respectively.
_   The head usually contains metadata being used by the page. The body contains the main content and information of the web page. The body contains the text, links, images, lists, and other data to present, all tagged appropriate.
_   Although the structure is tagged, HTML is not meant for styling information. To add aesthetics like fonts and colours, a cascading style sheet (CSS) is applied. CSS references the standard HTML tags to apply specific styles to text within those tags. CSS is applied either via a separate CSS file or directly within the HTML document.

XML:
eXtensible Markup Language (XML) is a markup language meant to store and transport data. XML is both machine and human readable. XML is usually used to send structured data within a web-based system.
_   XML schemas can be defined for the valid tags and their appropriate structure for an XML document.

JSON:
JavaScript Object Notation (JSON) is a format used to store and transport data. It is designed to be both machine and human readable. JSON offers many benefits, because JSON can be easily converted to JavaScript objects, and vice-versa. JavaScript is an interpreted programming language commonly supported in modern web browsers.
_   This ability to easily convert to JavaScript objects and vice-versa makes JSON a popular format when transferring data between web browsers and servers, as well as for passing data around in web applications.
_   JSON data is written as name/value pairs with JSON objects written inside curly braces. JSON data can also have arrays of JSON objects. Arrays in JSON are written inside square brackets.

4.1.6 – HTTP
Hypertext Transfer Protocol (HTTP) is a protocol that dictates how information, including hypertexts, is transferred across the Internet.
_   Hypertext is a document embedded with hyperlinks, which when clicked, will take you to the intended document or resource. Hyperlinks were originally used to link HTML documents. HTTP was designed to facilitate the use of hypertext, and to support the communication of documents and resources expressed in HTML.
_   Over time, hyperlinks have been used to link together multimedia resources, such as images, videos, gifs, text, and audio, or documents containing any combination of these. Resources can be static, such as HTML documents, images, or videos, or dynamic, such as programs that produce some output when they are called.

URIs and URLs
Universal Resource Identifiers (URIs) are addresses used to identify resources. Universal Resource Locators (URLs) are a subset of URIs, that are used to locate resources. Both identify the resource, but URLs also tell the protocol how to locate and access the resource. URLs provide the protocol and domain name or IP address of the machine the resource is stored on, and the location of the resource on the machine. All URLs are URIs, but not all URIs are URLs.
_   The URI does not need to explicitly provide the IP address. The browser is able to resolve the IP address corresponding to the hostname provided in the URI. The browser will either already know the IP address corresponding to the hostname, or if it doesn’t know, it will query a Domain Name System (DNS) server to find out.

TCP
HTTP is built upon a client/server design. To accomplish this, HTTP is built on top of another protocol known as the Transmission Control Protocol (TCP). When a client makes a request to a server, this opens a TCP connection between the client and server allowing for communication. Messages are sent and received through TCP ports. The client/server relationship exists between a web browser and a web server.
_   HTTP relies on TCP connections as they allow for reliable, ordered, connection oriented communication. When a browser accesses a URI that starts with “http”, a connection between the web browser and a web server is opened on TCP port 80. This port is the default for HTTP messages.

HTTP Requests and HTTP Responses
A client request consists of a request-line, headers, a blank line, and sometimes a message body.
    _Request-Line: The request-line includes the request method, request URI and protocol. The URI may end in a query string to specify parameter data for the request, although this is optional. This string is separated from the path of the resource by a question mark.
    _Headers: Client requests may have a various number of headers, of different kinds. Headers may be mandatory or optional. Mandatory headers allow for the request to be processed and optional headers can be used to give context to the request. Two mandatory headers in any request are the host header, which contains the domain name or IP address of the host, and the accept header, which informs the server what kinds of content the client will accept as a response. Further, if a message body is present, then a content-length header that indicates the size of the body in bytes and a content- type header that indicates the type of the body must be included.
    _A Blank Line: A blank line follows headers. If no message body is required for the request, then the request ends here.
    _Message Body: This section contains the message body, if it is required for the request. Message bodies might be HTML documents, JSON, encoded parameters, or other similar content.

Server Response
A server response consists of a status-line, headers, a blank-line, and sometimes, a message body.
    _Status-Line: The request-line includes the protocol version and the HTTP status code. The HTTP status code informs the client of the status of the request. There are many possible HTTP status codes. If the request has been successfully processed, the status code of “200 OK” will likely show.
    _Headers: As with client requests, server responses may have a various number of headers, of different kinds. Headers may be mandatory or optional. Many optional headers exist and can be used to provide more information and context about the communication. If a message body is present, then a content-length header and a content-type header must be included.
    _A Blank Line: A blank line follows headers. If no message body is required for the response, then the response ends here.
    _Message Body: This section contains the message body, if it is required for the response. Message bodies might be HTML documents, JSON, encoded parameters, or other similar content, as with HTTP requests.

Encoding
HTTP limits the characters used in URIs, request queries and request bodies to be ASCII. Special or unsafe characters, like space or Unicode, require the encoding of these characters. An example of an unsafe character is a “space”.
_   Unsafe characters are often replaced with a “%” sign, followed by their two-digit hexadecimal digit encoding. For example, a space can be encoded with “%20”, or with a “+” sign. The phrase “software design and architecture” can thus be encoded either of the following ways:
    _software%20design%20and%20architecture
    _software+design+and+architecture
_   Query strings can also be encoded, using the “=” sign. For example:
    _colour=red
    _height=very+tall
_   The ampersand symbol, “&”, is used to join all the parameter value pairs. For example:
    _colour=red&height=very+tall

GET Method
This lesson has reviewed HTTP requests. Each HTTP request must indicate a request method in its request-line. Request methods are used to indicate to the web server what it should do with the request. The most common request methods are: GET, POST, and PUT.
_   The GET method retrieves the resource given by the URI provided in the request-line. Get methods are used to retrieve web pages, images, or outputs of programs. A query string may be sent along with the request in the URI. Queries always start with a question mark and must be url- encoded. No message body is sent along with a GET request.

POST Method
The POST method is another example of a request method. The POST method is used to add or modify a resource according to the message body of the request, on the host specified in the URI of the request. The message body contains the information used to create or update a resource on the website.
_   POST requests are often used by HTML forms to submit data. If the data in the message body is from an HTML form, then like a GET query, it is url- encoded.

PUT Method
The PUT method is another example of a request method. The PUT method takes the information provided in the body of the request, and creates or updates a resource at the location specified in the URI of the request. The URI specified in the request dictates to the server the identity and location of the enclosed resource.
_   The PUT method can be used to create or update a resource, like the POST method. The information contained in the request body of a POST method, however, is created or updated under an identity and location determined by the web server, which is not necessarily the identity and location in the supplied URI.

HTTP Statelessness
HTTP can also be stateless. This means that the relationship between requests is not preserved.
_   For example, if a user were browsing an online shopping website, and clicking different items, the HTTP protocol does not keep track of which items have been previously clicked. Every time a new item is clicked, a new request is sent, but the protocol is unaware if the same client is making the request.
_   HTTP cookies can be used by websites to track the behaviour of users on the site. When a client makes a request, the site gives an HTTP cookie to store information about the user’s browsing session. The cookie is stored by the client, and updated by the server each time the client makes a request to the server. This allows the server to store state information about interactions with a particular client, which can be useful for tracking purposes.
_   HTTP is fundamental for the web, as it dictates how data is communicated and exchanged. This makes HTTP very important for invoking and accessing web services, and enabling a service-oriented architecture.

4.1.7 – JavaScript
Javascript is a programming language that can be used for a variety of purposes. Javascript is able to modify elements, attributes, styles, and content within the HTML document. Javascript can be embedded between “script” tags in HTML (<script></script>).
_   Javascript is able to provide interactive elements to web pages, because it is an interpreted language. This means that Javascript code is interpreted by a web browser at run time. In other words, embedded Javascript is a series of commands that are executed by the web browser when it loads the HTML document.
_   It is possible for web pages to provide some interaction to users without Javascript, through the use of HTML forms that submit POST or GET requests. The web server responds to the request by providing the web browser with a new HTML document. The result of the interaction will be visible only after the browser has received and loaded the new HTML document. However, interactions provided to users on a web page embedded with Javascript tend to be more efficient and more usable. With Javascript, a form can be partly checked and processed on the client-side. This means that the browser does not have to wait for the web server to provide a new page, instead, the Javascript on the page can dynamically change the HTML web page that is already loaded in the browser as it runs the client- side in the browser. This offloads some of the processing required to operate this application so that not everything needs to be processed server-side.
_   Javascript is able to modify elements on a web page by making use of the HTML Document Object Model (DOM). When a page is loaded in a web browser, the HTML document becomes a document object. This object can be used by Javascript to obtain and modify the elements and content on the web page. As a result of processing the document object, the content, structure, and style of an HTML document can be modified.
_   For example, Javascript can be used to modify elements on a web page, such as providing the ability to make image thumbnails grow in size when clicked, and shrunk back down when clicked again, or to hide and reveal text, as for spoilers on text-based web pages.

4.1.8 – Remote Procedure Call (RPC)

Distributed Systems Basics
_   Modern client machines are not as powerful as their server counterparts. Client machines are designed to address a different set of concerns than servers in heterogenous environments. For example, client machines may be designed for the experience of a single user, and may be focused on providing exceptional usability. Their operating systems are therefore designed to be intuitive to use and to learn. A server, on the other hand, may need to provide computing power to multiple, concurrent users. Servers are typically used by system administrators, or other information technology professionals. Their user interfaces may require more expertise to use. Since machine and operating environments are different between clients and servers, they communicate with the help of middleware.

Middleware
_   Middleware is a type of architecture used to facilitate communications of services available and requests for these services between two applications that are operating on environmentally different systems.
_   Network connectivity is an expected mode of operation for modern systems, which rarely work in isolation. New software systems are designed to be able to communicate with other systems over a network. Legacy systems are commonly updated, redesigned, or rewritten in order to be able to utilize network connectivity.
_   Computer networks have enabled the growth of distributed computing. Distributed computing is a system architecture in which computers on a network are able to communicate and coordinate their actions by passing messages through a network.
_   Computer networks have enabled the growth of distributed computing. Distributed computing is a system architecture in which computers on a network are able to communicate and coordinate their actions by passing messages through a network. Distributed computing has enabled developers to design tiered architectures with each layer focusing on specific aspects of the overall systems. Clients and servers can be designed to be specialized, and software and hardware developers are able to create software environments and machine architectures that serve to enhance these specialized characteristics.
_   Increased specialization runs the risk of impeding communication between client and server. To solve this, middleware provides a common interface to clients and servers in heterogeneous environments. Middleware facilitates communication on a large scale by providing a common interface between entire distributed systems.
_   Middleware allows developers to access functionalities of a system, without having to implement an entire tier of subsystems in their architecture. There is a need for middleware to become more sophisticated, or for existing middleware to be extensible, as modern systems become more and more complex. As systems move towards n-tiered architectures, middleware needs to be able to encapsulate more functionalities, from business logic and distribution of client requests to being involved in handling authentication and authorization.

RPC
_   One example of middleware is remote procedure call (RPC). RPC is the basis for middleware systems used for certain web services. RPC allows clients to invoke procedures that are implemented on a server.
_   In RPC, the client and server are either:
    _1. on completely separate machines: the physical address space between client and server is clearly different, so the client does not know the physical memory address of the procedure that it wants to call in the server since they do not share the same physical memory.
    _2. are a different virtual instance on the same machine: the “virtual” address is shared between client and server. It is up to the operating system to manage each individual virtual instance, and find the correct virtual address for the procedure being invoked.
    _In either case, the client cannot directly access the procedure being called.
_   RPCs became successful because they did not require developers to learn a new language or programming paradigm, but instead used the familiar concept of procedures. Distributed systems could be designed and implemented more efficiently. RPCs are currently used in many different configurations – they can be stored procedure calls in a database system, or in XML messages for web services.
_   Basics of RPC: The client, the server, and the interface language definition (IDL) are the three primary components of an RPC.
_   The IDL is the first component implemented. It defines what procedures on the server are available to the client. It also describes the input parameters, as well as the returned response. In other words, the IDL is the specification for remote procedure calls. It tells the client what remote services are available, how they are accessed, and what the server will respond with.
_   Once the IDL is compiled, the client and server stubs are produced. They perform the “heavy lifting” with interface headers.
    _The client stub: in particular acts as a proxy for the procedure call. It is responsible for:
        _Establishing the connection with the server through a process known as binding,
        _Formatting the data to a standardized message structure, such as XML,
        _Sending the remote procedure call,
        _Receiving the server stub’s response.
    _The server stub in an RPC receives the call, and invokes the desired procedure. The server stub also contains the code for receiving the remote call, translates the standardized message into a data format the server recognizes, and sends the server’s response back to the client stub.
_   Stubs are compiled and linked directly to the client or server component. When a client makes a remote procedure call, the invocation will act like it is a local procedure call to the client because the client stub is in the same address space. In order to create client components in environments that are different than the server, it is possible to create more complex server stubs. For example, complex stubs can allow client components operating on a Windows machine to communicate with server components that are running on Unix.
_   IDL allow stubs to be generated because the IDL maps the concrete programming languages to the intermediate representation in the stub. This is preferable to manual development of client-server stub pairs that can communicate with each other, as there are so many programming languages and operating platforms.
_   The interface headers: are a collection of code templates and references that are used to define what procedures are available at compile time. These files are used in the development of the client and server components. The basic types of interfaces provided to make a remote procedure call:
    _Procedure registration: Tells the client what procedures are remotely accessible on the server.
    _Procedure call: The actual procedure that is being invoked on the server.
    _Procedure call by broadcast: The same thing as a procedure call but these procedures are invoked by broadcast.
_   The stubs abstract all the networking details, which can be kept hidden from the developer so that they don’t have to worry about them. RPC does allow configuring of connection settings if the developer wants more control over the details of the client-server connection.
_   How RPCs are Performed: There are seven steps to performing RPCs:
    _1 Client component invokes the procedure: The client component makes the procedure call, and passes the arguments to the client stub. Since the client stub is linked to the client, no network connection needs to be made. This step is exactly like a standard procedure call.
    _2 Client stub marshalls the parameters: The client stub converts the parameters to a standardized message format and copies them into the message through a process called “marshalling”. The parameter data is transformed into a format that is suitable for communicating with another application. The format used is determined by the IDL that is used to compile the stub.
    _3 The message is sent to the server: The client stub sends the message to the server using the binding information that it is given. Binding is the process in a client that connects to a server. It can be done statically or dynamically. Static binding uses hard coded binding information. With static binding, if the server goes offline, then clients will not be able to establish a connection. Static binding also does not allow for server redundancy, since clients will always connect to a specific one. Dynamic binding is more complex and adds another layer to your tiered architecture. This added layer is referred to as the name and directory server. It is responsible for keeping track of which servers have been bound, and balancing the load between all servers. This layer can also keep track of servers and change the binding information if the servers change. The client stub is responsible for the static binding or communicating with the dynamic binding layer, so the developer of the client component does not need to worry about binding.
    _4 The server stub receives and unmarshalls the message: The message is received by the server stub. Since the arguments have been marshalled, it must be translated back to a format that is usable for the server-side procedure call. This is done in a process called “unmarshalling”. Once the arguments have been converted back to the proper format, the server stub will invoke and pass the arguments to the procedure in the server component. Just like on the client side, this procedure call looks like a normal procedure call to the component, because the server stub is linked to the server-side component.
    _5  The server component executes the procedure and returns the result to the server stub: Once the procedure finishes execution, the server component will return the results back to the server stub. In order for the results to be returned back to the client, the server stub needs to marshall the results into a standardized format.
    _6  The results are returned back to the client stub: The server stub does not need to bind to the client because the connection is already established by the client. All the server stub needs to do is return the message back through the connection.
    _7 The client stub receives and processes the results: The client stub unmarshalls the results in the message, and then returns it to the client component. The client can now close the connection to the server.
_   Synchronous RPCs: Originally, RPCs were designed to be synchronous. During a remote procedure call, the client component pauses its execution while it waits for a response. This is also known as blocking, since the client cannot perform any other task until the server returns a result. Waiting for a response can introduce a number of issues:
    _If the server never returns a response, the client can end up waiting indefinitely.
    _It may not be clear how long to wait for a server to response. Some procedures may take longer than others, or the server may take longer to create a response under a heavy load.
    _The RPC may need to be re-transmitted, and this can be difficult to determine.
_   Asynchronous RPCs: Modern systems need to be able to handle remote procedure calls in an asynchronous manner. Asynchronous systems are considered non- blocking, because clients do not need to wait for a server response before moving onto another task. This allows components of a distributed system to work independently. Systems are also able to perform different tasks in parallel with each other because they do not need to wait for one task to end before starting another. Asynchronous behaviour adds more complexity to a system, because how the system allocates resources for various pending tasks needs to be managed. Note that overloading a system with asynchronous tasks can also reduce the system’s overall performance.

4.1.9 – Object Brokers
Systems and their standards must evolve as new programming paradigms are introduced. However, it is expensive to design and create new systems from scratch, particularly as the design of older systems can still be applicable and relevant. In some cases, it may be more efficient to update existing architectures using the new paradigms. Remote procedure calls evolved in this manner. Instead of being relegated to be a legacy system, they have been used as the basis for a middleware architecture based on object brokers. Object brokers combine the distributed computing aspects of remote procedure calls with object-oriented design principles. By including object- oriented programming, object brokers simplify and allow distributed systems to use an object-oriented approach.
_   Object-oriented programming also introduced two concepts that changed the way methods are identified: inheritance and polymorphism. These allow different classes to have different implementations of the same method signature. In previous programming paradigms, the signature of a procedure in a program was unique, which means that only a single implementation was possible. Allowing for different implementations of the same method signature caused issues for middleware. Middleware provides services for each object, and so middleware had to be able to take inheritance and polymorphism into account. Remote procedure calls therefore naturally evolved towards object brokers. Beginning in the 1990s, middleware began to be able to address handling object-oriented programming.

CORBA
_   The most common object broker architecture is the Common Object Request Broker Architecture (CORBA), although it can be more closely compared to a set of standards. CORBA provides an outline of what should be included in object brokers, although it is not a step-by-step guide for implementation. As numerous object-oriented languages exist, the primary goal of CORBA is to create a specification that allows object brokers to be independent of the programming languages used to implement clients and servers. Client-side and server-side operating systems are different because quality requirements are different.
_   CORBA ensures that developers are not restricted to a language or operating system (OS) requirements if middleware is required for a system. Similar to procedures in an architecture based on RPC, objects can be distributed among a network of computers, which allows them to reside in different physical address spaces. Alternately, objects can be distributed throughout different processes on the same computer, which lets them exist in different virtual address spaces.
_   CORBA allowed for the foundation of Microsoft’s .NET framework and the Java 2 Enterprise Edition framework offered by various vendors. CORBA contains three main components:
    _1. The object request broker: which provides object interoperability to the client and the server. An object must declare its interfaces before it can be accessed by a client or server through the broker. The broker is responsible for marshalling and unmarshalling all the method calls that it receives. This allows the client or server to be modified without affecting the other.
    _2. The CORBA services: are services provided by the middleware “to” the objects being used by the client and server. Services provided vary and may include functions needed for persistence to functions related to object security. All CORBA services are accessible through the CORBA standardized application programming interface (API).
    _3. The CORBA facilities: provide servers at an application level. These are usually high-level functions such as document management.
_   As object brokers are an extension of the RPC architecture, the architectural design of using an IDL, can be used to generate the stubs used to facilitate communications within the system.
_   In CORBA, IDL is enhanced over IDL in an RPC-based system, because the IDL is capable of supporting inheritance and polymorphism. All object interfaces must be declared in the interface definition language in order for them to be presented to the client. The CORBA IDL also has a standardized mapping to multiple object- oriented languages, which allows clients and servers to be developed in different programming languages. Standardization also allows the IDL to be portable across brokers by different vendors.
_   The CORBA IDL compiler is responsible for constructing the client stub and server skeleton. The client stub, and server skeleton have similar functionality to their RPC counterparts. However, as CORBA deals with objects, the stub and skeleton need to be built upon in order to be able to handle objects.
_   The client stub acts as a proxy object. It hides all the objects that are distributed and being served by the brokers. Since the objects are hidden and the stub is linked to the client application, all method calls to the objects being served appear as if they are local invocations. Further, as the client accesses the remote methods through the stub, the stub must also contain the method declarations of all the objects distributed throughout the brokers.
_   The server skeleton hides the object distribution from the server application. The skeleton acts as a proxy object, since the remote objects are making functions call to the server. This makes it appear as if the calls are coming from a local object.
_   This architectural design means that the client needs to know the server’s IDL in order for the two to communicate with each other. Without this knowledge, your client will not be able to access the methods that are being served by the object broker.
_   Interoperability can only be achieved if the client binds to at least one broker. Without binding, the client cannot access the behaviours of the objects. Binding can occur statically or dynamically:
    _Static binding occurs when the client stub is created. The service that is used for static binding to a broker is handled by the IDL. When the IDL compiler generates the stub, it will be statically bound to the broker that the IDL compiler belongs to.
    _Dynamic binding is also specified in CORBA. It allows clients to dynamically search for new objects, retrieve their interfaces, and instantiate the discovered objects. In dynamic binding, the IDL compiler does not need to generate a stub, but requires two additional components instead:
        _1. The interface repository, which is used to store the IDL definitions for “all” the objects being served by a broker.
        _2. The dynamic invocation interface, which provides all the necessary operations that a client needs for browsing the interface repository, and dynamically constructing methods based on what the client discovers. Object references are provided by two services in the dynamic invocation interface component, allowing for two ways for clients to search for and discover new methods:
            _a. The naming service allows the client to retrieve objects using the “name” of the interface that the client needs.
            _b. The trading service lets the client search for objects based on object attributes.
_   Building dynamic invocation interfaces is semantically difficult. It is key to put effort into building the logic for the component. The searching semantic is difficult to implement – the client needs to understand the meaning of each service property in order to properly search the repository for services. A naming convention therefore needs to be implemented so that both the client and the dynamic invocation interface can understand each other. For example, the term “get” can have synonyms such as fetch, retrieve, and obtain. The client and the dynamic invocation interface needs to be able to identify that all those words mean the same thing. The client also needs to know how to interact with the services that are discovered, or it will have a hard time determining what the behaviour of a newly discovered service is, what the parameters mean, or in what order services need to be invoked so that the desired effect is achieved. The disadvantages of implementing semantic rules for dynamic invocation interface generally outweighs the advantages. This is especially true in large and robust object brokers because there are more semantic ties to discover and implement.
_   Using CORBA as a middleware system presents many benefits. These include:
    _Being able to handle distributed computing in an object-oriented paradigm.
    _Objects are essentially independent of the physical and virtual address, as they can move around but still be referenced. The broker keeps track of and maintains both the references made to the objects and the actual address of the objects, while a client only needs to make references to the objects. If an object moves, the client will still have access to it. This benefit allows development of clients and servers to occur without restrictions from programming languages and operating systems.
    _CORBA provides a variety of options in regards to data. Data can be strongly or dynamically typed. It can also be marshalled into binary form or compressed in order to reduce the size of the data that is sent.
    _CORBA provides standards for optimization by allowing developers to manage threads and network connectivity settings.
_   As with any architectural standards, CORBA has disadvantages. Most of the problems that arise from use of CORBA are not related to the standards themselves, but instead result from poor implementation of those standards:
    _Any system that does not implement the CORBA standards correctly will suffer. Issues will usually occur in the broker of the system, which can lead to complex and incoherent API, difficult to use object brokers, and overall poor performance. Poor implementation can occur because of inexperience in development, or the need to reduce cost.
    _Although CORBA is advantageous in that it provides objects that are not restricted to a physical or virtual address, this design also causes location transparency, which means that even if objects that interact exist in the same physical or virtual address space, they are still treated as if they were in different spaces. Because of this, method calls are always made in the most complex way possible regardless of where objects are located.

4.2.1 – Introduction to Web Services
In order for services to be able to be used by other processes, there must be some way of “exposing” the service. In other words, services have interfaces that can be used by some service requester. It follows then that a web service is exposed and accessible using web technologies.
_   Enterprise Application Integration (EAI) is an enterprise-level solution for integration problems in integrated systems. The exact architecture for EAI varies, but it does use middleware.
_   Rather than deal with multiple combinations of connections, middleware ensures that a system has fewer interfaces to implement and maintain. However, implementation in business to business (B2B) interactions, where interactions are between business instead of within them, is not always clear. For example, identifying which business implements the middleware, managing security, and protecting data from outside influence can complicate B2B implementation of EAI. Consequently, EAI is not used for B2B interactions.
_   To solve these issues, web services are implemented for interactions between businesses. Web services are usually implemented with a specific set of standards and protocols for implementing services over the web. Web services are defined by the World Wide Web Consortium (W3C) as “a software system designed to support interoperable machine-to-machine interaction over a network”.
_   The technologies and standards that make up
web services are:
    _Web Infrastructure: Web services are built on top of web infrastructures. They start with TCP, the networking protocol responsible for reliable, ordered, connection- oriented communication. On top of that is HTTP, which web services use to send information and interact with their clients. Other transfer protocols exist as well as HTTP. HTTP however is compatible with nearly every machine and provides a strong foundation for platform independence and interoperability. HTTP is the basis for web services such as RESTful web services.
    _Invoking (SOAP): In order for a service requester to use a particular service, it must invoke it. Invoking is like a method call in an object-oriented language, except that it must be done through a request in XML. Invocation will include which operation is requested along with the parameters and data. In web services, invocation is done with SOAP, a protocol specification that is based on XML and allows services to send information to one another. Service requesters and service providers use these SOAP messages to send each other information. Since this is done through XML, systems coded in different languages and on different platforms can easily communicate.
    _Describing (WSDL): Services must know how to interact in order for interaction to take place. Web Service Description Language (WSDL) is the standard protocol for describing the interface of a service. WSDL are written in XML. A WSDL description will describe the interface of a service in a machine-readable fashion, so that a service requester can bind itself to this interface. Binding is the act of generating the necessary code to interact with a service so that a service requester can begin invoking it. If a service interface is described unambiguously with WSDL, binding can be done by generating the necessary code automatically.
    _Publishing and Discovery (UDDI): Service requesters and service providers need ways to come into contact. Universal Description, Discovery and Integration (UDDI) is used by service providers to publish descriptions of their services. Service requesters looking for a service can search by the WSDL descriptions or other aspects of the service. This is called discovery.
    _Composition (WS- BPEL): Various standards can be built on the foundational standards of SOAP, WSDL, and UDDI for web services. These standards usually have the prefix WS, such as WS-Security for adding  security functions, or WS-Coordination for coordinating the activities of many services. WS-BPEL is one of these standards, for Business Process Execution Language (BPEL). BPEL facilitates service composition as it allows developers to combine existing services into new, composite services. Composite services are services built with other services, which can be basic services which do not rely on other services, or can be other composite services.
_   Together, SOAP, WSDL, and UDDI are the three foundational standards of web services. They allow for web services to be invoked by service requesters, to describe themselves, and to be published to registries where they can be discovered. All of them rely on web infrastructure.
_   The standardization of how web services invoke, describe, and publish means that their internal implementation does not matter. Service requesters and services can effectively interact despite being on different platforms and in different languages. However, the commands and parameters of the standards must be supported by the service provider. The use of web services makes building interfaces easier, because communication between services and service requesters is standardized. Although interactions are pair-wise, they are implemented with web service standards, so applications can be developed in any language and on any platform that supports standard web technology.
_   Web services can take on the role of middleware, and facilitate interactions between processes for business-to-business interactions. Businesses can control how they interact by choosing how to expose their services. They also do not need to provide a different interface for each outside company.

4.2.2 – Service Invocation (SOAP)
Web services use a form of XML messages for communication between service requesters and service providers. The request-response messaging pattern is the basis of all interactions between web services and the software that uses those services. These XML messages conform to SOAP, a standard developed at Microsoft. SOAP allows a service requester to invoke services. It provides standardization to interactions between service requesters and service providers, or clients and servers. The way that XML defines and organizes requests and responses must be standard so that both parties can understand it.
_   Two “styles” of SOAP messaging exist. SOAP does not dictate which of the two styles to use. Both styles are commonly used:
    _Document Style SOAP: In document style SOAP, a SOAP message is a structured document that contains a request that will be understood by both parties.
    _RPC Style SOAP: In RPC style SOAP, the body of the message is similar to a method-call, that consists of an operation and input parameters.
_   SOAP messages are sent over a transport protocol. For example, Simple Mail Transfer Protocol (SMTP) is used for email. This lesson will focus on using HTTP. SOAP messages are sent using HTTP POST. HTTP determines where to send the request, since this information is not directly included in the SOAP message itself. Since HTTP must acknowledge a POST request, it could return the response, or a simple acknowledgement that the request has been received.
_   Messaging is synchronous if the service request waits for a response before continuing. A program might be left doing nothing while waiting for a response, particularly if the availability or response time of a web service is an issue. Messaging is asynchronous if interactions allow the code to keep executing. This means that when a message returns from the service provider, the code can process it.
_   A simple implementation of an SOAP request starts when the client code makes a local call to a stub. The stub then converts the request into a SOAP message. This SOAP message is packaged into HTTP and sent to the service provider. When it arrives, the HTTP server passes the content to a SOAP router. The SOAP router determines the appropriate server stub and delivers the message. The server stub uses the information of the SOAP message to make an appropriate method call. Once the service code handles the request, the process works in reverse to send this response.
_   Four basic messaging patterns exist for SOAP. More complicated messaging patterns exist and are required for meaningful interactions. Since SOAP messages are stateless, these interactions are implemented by relating messages another way, like storing the interaction state on the client and/or the server, or by using extensions to web services like WS- Coordination. Messaging
Pattern:
    1_ Request-response: In a request-response pattern, the server requester first sends a message, then receives a reply from the service provider. This process is synchronous and can be implemented over HTTP.
    2_ Solicit-response: In a solicit-response pattern, the service provider makes a request to the service requester. This process is synchronous, and is often a confirmation.
    3_ One-way: In a one-way communication pattern, the service requester sends a request to the service provider, but no response is expected. This could be a simple notification that the service requester is up and running. This process is asynchronous.
    4_ Notification: In the notification messaging pattern, the service provider sends a notification to the requester without expecting a response. This model is well-suited to event-based systems where there are publishers and subscribers. This process is asynchronous.
_   SOAP messages have certain disadvantages, which fall beyond the scope of this lesson. Some of these disadvantages include the fact that XML encoding and decoding adds overhead and does not easily accommodate some data types. These disadvantages have resulted in SOAP being superseded in many applications by methods that use HTTP more directly, such as RESTful web services. SOAP and its related web service infrastructure were the basis of the first major consensus on web services. SOAP’s neutrality allowed systems on different platforms and in different languages to interact and pass data. The XML-based structure allowed for machine-readable data that could be manipulated by any machine connected to the internet.

4.2.3 – Service Description (WSDL)
In web services, Web Service Description Language (WSDL) is a standard used to describe the interface of a web service. This helps SOAP messages find services, and understand how to interact with services, including parameters. WSDL descriptions can be read by potential service requesters, either programmatically or by developers. WSDL was created by Microsoft, IBM, and Ariba by combining various attempts at standardization. WSDL descriptions are written in XML, and can be compared to method signatures in object-oriented programming.
_   WSDL descriptions include how to structure a request, the input parameters required, the data the service will output, the location where the service requester will send SOAP messages, the transport protocol it will be sent on, and more. The WSDL description helps the service requester determine how to request the service. WSDL descriptions are machine-readable, which allows the service requester to generate necessary code to interface with a service provider automatically. This process is known as binding, whether or not it is done automatically or by the developer. Only after binding can the service requester invoke the service using SOAP messages that they structured with the help of WSDL descriptions.

WSDL Description:
Let us examine the general form of WSDL descriptions. WSDL is modular, which means that it is made up of different components that can be combined to define the desired interface or multiple interfaces. WSDL descriptions can even import other WSDL specifications by importing their descriptions and using them to combine into new interface descriptions.
_   There have been several versions of WSDL. The previous versions used different terminology and structure, although concepts remain largely the same. Some of the most important part of a WSDL 2.0 description are:
    _Types: which describe the data types that are used. Developers can define abstract data types in XML. If only basic data types already available in XML are used by interactions, then this part is not needed.
    _Interfaces: describe interfaces to the services provided in terms of what operations can be performed and in what order. The order of operations can be described by the message exchange patters of request-response, solicit-response, one-way, and notification. Interfaces were formally called portTypes in WSDL 1.2. Interfaces are abstract. They cannot be used until they are bound to the concrete implementations that are needed to use web services.
_   The categories used to bind interfaces to concrete implementations are:
    _Bindings: which determine how the SOAP message is translated into XML, and dictate the form of the messages. This includes specifying between document-style and RPC-style interactions, as well as specifying the transport protocol on top of which the SOAP messages are sent.
    _Services: which bring together interfaces and bindings, and assign them to endpoints or ports. These are located with URIs.
_   WSDL provides a robust, modular, and extensible service description language. WSDL description enables reuse because WSDL descriptions are broken into very fine descriptions which allow for the reuse of parts of WSDL specifications in different ways. WSDL documents can also import other WSDL documents, gaining them access to data types in the imported WSDL description or to interfaces.
_   WSDL descriptions, as an XML-based approach, like other aspects of web services, allow for interoperability between different platforms over the Internet. WSDL can also describe non-XML based services. However, like SOAP messages, encoding and parsing XML imposes computational costs. This is the major disadvantage of XML-based standards.

4.2.4 – Service Publication and Discovery (UDDI)
Web services need to be published and discovered. Developers need to be able to find services to build apps, and there needs to be a way to get people to use these created services. The advent of the Internet helped customers find services through search engines. However, it is important to advertise web services. This is known as publishing. The first framework for publishing was Universal Description, Discovery, and Integration (UDDI).
_   UDDI was created in 2000 by Ariba, Microsoft, and IBM, but it is now managed by the Organization for the Advancement of Structured Information Standards (OASIS), which is a non-profit organization that also manages a number of other open standards. UDDI was intended to be used to specify a universal registry and broker of web services, using XML and WSDL to structure data about the web services and how they were provided.
_   UDDI is a protocol for publishing and discovery, and not a necessary component of implementing web services, it is not tied to a specific registry. If the web services to use and the binding is known, then a discovery mechanism is not needed. Conversely, if a service is developed for use with a few specific applications, and it can be bound to those applications directly, then the web service does not need to be published. However, UDDI, is a useful standard for bringing service requester and service providers together.
_   UDDI allows service providers to publish their services to a UDDI registry. Once they are published, potential service requesters can search the registry and discover the service they need. This is done by searching elements of the WSDL description, or other descriptions of the service or service providers. Bringing service providers and service requesters together is an essential part of creating an effective service ecosystem.
_   Once the service that the service requester wants to use is found, the service requester can bind to it using the WSDL descriptions. After the service requester is bound to the service by generating the code for the necessary messaging patterns, the service requester can invoke the service.

Publishing:
Publishing registers information about the service with a UDDI registry, which includes information about the service provider, the service itself, and various technical descriptions of the service. A uniform resource identifier (URI) is assigned to the service by the UDDI registry. The URI is a unique reference used to invoke the service.
_   Information encapsulated in the UDDI standard is contained in three categories. These are:
    _1. White pages, where information such as the business name, a short description, contact information, and unique business identification numbers is stored.
    _2.Yellow pages, which contain information about the service or industry that the business is in, including hierarchical information about the business. For example, exchange rates are a subset of currency services.
    _3. Green pages, which contain the technical details of how to use the service.
_   Information encapsulated in UDDI also falls into four data structures. These are:
    _1. businessEntity, which contains information about the business. This roughly corresponds to the “white pages”.
    _2. businessService, which describes the services that the business is offering. A business can have many services, but a service can only have one business that owns it. This roughly corresponds to the “yellow pages”.
    _3. bindingTemplate, which gives the necessary information needed to invoke the service in question. It is a description of the interface needed for communication. A service may have more than one bindingTemplate. This, along with the tModel, roughly corresponds to the “green pages”.
    _4. tModel, which gives more detailed information about the service. This may include references to the protocols used by the service or detailed technical specifications of the service. The tModel is a flexible data structure; it can represent any abstract concept, and tModels can be nested to provide various meanings. For web services, one of these tModels will reference a WSDL description of the service. This with the bindingTemplate, roughly corresponds to the “green pages”.

Publishing and Discovery as Services:
UDDI specifies web services for publishing. Service providers publish, including adding, deleting, and modifying entries to a registry through SOAP messages. Operations could be save_business, save_service, save_binding, save_tModel, or delete commands for these same elements.
_   UDDI also specifies web services for discovery. These are accessed by SOAP messages. Commands to search for services include find_business, find_service, find_binding, and find_tModel. Information can be requested with commands such as get_businessDetail, get_serviceDetail, etc.
_   Service requesters use these commands to find and get information about the service interface. Once the service requester has information about the service interface, it can generate the necessary code to access the interface for the service. In other words, it can dynamically bind to it. Publishing and discovery are often hidden from the developer. Instead, developers often use web portals to search for services.

Dynamic Binding:
Binding can be a highly dynamic, run-time activity, although this has repercussions for a developer. For example, it may prevent a developer from knowing what errors might occur or what exceptions may be generated, and thus from developing robust code. Or a web service provided by a business may require contracts or agreements, which are managed by people and not programs. Consequently, service discovery is usually a design-time activity. Binding can still be automated, although this may be challenging as it would require the interface description to be completely unambiguous.
_   Discovery is usually performed by a human developer, while binding is at least monitored and tested by a human developer.

4.2.5 – Service Composition (BPEL)
Composition is the action of coordinating several services and providing an interface. A service is composed when it is made up of other services. Further, a service that is composed of other, lower-level services may be used to compose higher-level services. This is comparable to the composing objects principle in object-oriented design. New functionality can be created by combining existing functionality, and encapsulating the new functionality as a service. However, web services are not usually compiled and run in the same physical location like objects.
_   Composing services involves invoking services in a certain order and handling exceptions that may arise. Services that comprise a composite service still remain separate from that service. A composite service could be like a “script” that uses other services according to some pre-determined order.
_   Middleware services can be difficult to compose, because their interfaces are not standardized. By extension, wrappers had to be developed as needed, so that components could interface with each other or with the middleware.
_   Web services, on the other hand, can be easily composed. This is because web services are accessed in similar ways. However, the problems that come with combining services do not go away with web services, they are just easier to manage. This module has examined services invoked with SOAP messages, described by WSDL, and catalogued by UDDI.
_   Composing a service from other services is similar to a business process. Business processes are easily mapped to activity diagrams. The beginning and end of a process are the points where the composite service is exposed to service requesters.
_   Basic services often have low-level, basic functionality. This functionality can be combined into higher level functionality with Business Process Execution Language (BPEL), the standard high-level composition language for web services, also known as WS-BPEL. WS-BPEL can then expose this higher-level functionality as a service which can also, in turn, be composed into higher-level services. Lower-level details of inter-service communication are dealt with by protocols such as SOAP and WSDL.
_   BPEL allows developers to compose compatible services into a business process that is itself exposed as a service. These services can be from external sources, on the Internet, or internal to a company or organization. Essentially, BPEL allows developers to create new services by composing them with existing services.
_   BPEL supports basic operations like “if-then-else” decisions, or other logic from various program languages and wrappers.
_   In addition to composition, web services are also associated with coordination. Coordination is when a process coordinates the activities of two or more services. Composition is distinguished from coordination because it exposes the collection of actions as another service.

S3 - 4.3.1 – Introduction to REST
Representational State Transfer (REST), a client-server architecture based on a request response design. REST is used in distributed applications by using HTTP to send messages to communicate between components.
_   The client sends a request and the server responds, but in REST, the communication is resource-based. This means that messages are sent as representations of resources. Resources can be any pieces of information that are self-contained. This can include documents, images, object representations, etc.
_   REST Restraints. REST is defined by five constraints. These are summarized:
    _Client-server architecture: A client-server architecture applies separation of concerns by having client and server roles with specific responsibilities that interact with each other. Servers provide services to clients, and clients provide users with a user interface to access services. Client-service architecture allows REST applications to be highly scalable and allows client and server development to occur independently. The client can be improved to provide users with simple and fast user interface without affecting the server, while the server can manipulate larger sets of data because it is freed from having to implement any client responsibilities.
    _REST is a layered system: REST can consist of multiple architectural layers of software or hardware called by the client and server. These layers can be used to improve performance, translate messages, and manage traffic. This helps to improve reusability of REST web services because layers can be added and removed based on the needed services of the client.
    _Interactions must be stateless: In REST architecture, interactions must be stateless. This means that the server does not save information about the current client state or previous requests made by the client. Servers are only aware that the client exists when a request is made. All necessary information for the server to understand and respond to the request comes through with the request, and requests are contained from one another. This improves the performance of web services, as servers do not have to remember the current states of clients in the system. The trade-off, however, is that this imposes significant restrictions on the way a client and server communicate. Every time a client sends a request to a server, it must provide and store information about its current state.
    _Clients can cache responses: This constraint means that clients can keep a local copy of a server response to use for later requests, depending on what information the servers add to the response to label it as cacheable or non-cacheable. This can help improve performance by reducing the number of requests for the same resources, and help to ensure that the client does not keep redundant or useless data.
    _There must be a uniform interface for communication between the client and server: This constraint has certain impacts. The first is that there are specific methods that can be understood. REST uses the common HTTP methods, GET, PUT, POST, and DELETE, to communicate different actions the client wants to perform on the resources. The second is that the resource must be identified in the request with a specific Uniform Resource Identifier (URI). Finally, the representations of the resources are uniform. Responses have specific headers, and the resource is written in three specific ways: XML, JSON, or simple text.
_   These constrains make REST a flexible, high-performance architectural style for building service-oriented systems based on web standards. REST provides benefits including high scalability, reusability, and loose coupling that allow it to meet the needs of modern applications with millions of users.































